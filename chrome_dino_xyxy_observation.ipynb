{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:09:49.469328Z",
     "start_time": "2025-11-13T19:09:49.338016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# to capture game screen\n",
    "from mss import mss\n",
    "# to provide keystroke inputs to the game\n",
    "import pydirectinput\n",
    "import numpy as np\n",
    "# to perform OCR on game screen\n",
    "import time\n",
    "# to create custom gym environment\n",
    "from gymnasium import Env\n",
    "# to define action and observation space\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "\n",
    "# 0: 'bird'\n",
    "# 1: 'cactus'\n",
    "# 2: 'restart'\n",
    "# 3: 't-rex'"
   ],
   "id": "c9c51797646fb6da",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:09:51.999877Z",
     "start_time": "2025-11-13T19:09:49.767565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# code to detect the objects in image\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "yolo_model = YOLO(\"yolo_model/object_identification_model.pt\")\n",
    "\n",
    "def getObjectPositions(observation):\n",
    "        observation = cv2.cvtColor(observation, cv2.COLOR_GRAY2RGB)\n",
    "        results = yolo_model.predict(source=observation, conf=0.25, imgsz=640, verbose=False)\n",
    "        result = results[0]\n",
    "        boxes = result.boxes\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            return boxes.data\n",
    "\n",
    "        # Group boxes by class and find leftmost for each class\n",
    "        class_leftmost = {}\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            class_id = int(box.cls)\n",
    "            x1 = float(box.xyxy[0][0])  # leftmost x coordinate\n",
    "\n",
    "            # Keep the box with smallest x1 (leftmost) for each class\n",
    "            if class_id not in class_leftmost or x1 < class_leftmost[class_id]['x1']:\n",
    "                class_leftmost[class_id] = {'index': i, 'x1': x1}\n",
    "\n",
    "        # Extract the indices of leftmost boxes for each class\n",
    "        leftmost_indices = [info['index'] for info in class_leftmost.values()]\n",
    "\n",
    "        # Return only the leftmost boxes data\n",
    "        filtered_data = boxes.data[leftmost_indices]\n",
    "        return filtered_data\n"
   ],
   "id": "e26f9d63c75d9e7a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:09:52.891271Z",
     "start_time": "2025-11-13T19:09:52.888257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_onservation(filtered_data):\n",
    "    obs = np.array([-1, -1, -1, -1], dtype=np.float32)\n",
    "    # {0: 'bird', 1: 'cactus', 2: 'restart', 3: 't-rex'}\n",
    "    #cactus-x1, bird-x1, bird-y1\n",
    "    for box in filtered_data:\n",
    "        if int(box[5]) == 1:  # cactus\n",
    "            obs[0] = box[0]  # x1\n",
    "            obs[3] = box[0]  # speed\n",
    "        elif int(box[5]) == 0:  # bird\n",
    "            obs[1] = box[0]  # x1\n",
    "            obs[2] = box[1]  # y1\n",
    "    return obs"
   ],
   "id": "bdf9e62e40fbd86f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:32:31.165272Z",
     "start_time": "2025-11-13T19:32:31.155576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# creating the environment\n",
    "class WebGame(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([\n",
    "                -1,-1,-1, 0  #cactus-x1, bird-x1, bird-y1, speed\n",
    "            ], dtype=np.float32),\n",
    "            high=np.array([\n",
    "                640, 640, 256, 640\n",
    "            ], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "        # define the extraction parameters for the game\n",
    "        self.cap = mss()\n",
    "        monitor_2 = self.cap.monitors[1]\n",
    "        self.game_location = {\n",
    "            'top': monitor_2[\"top\"] + 150,\n",
    "            'left': monitor_2[\"left\"] + 400,\n",
    "            'width': 640,\n",
    "            'height': 256\n",
    "        }\n",
    "\n",
    "        self.objects_positions = []\n",
    "        self.pcx = 641\n",
    "        self.speed = 350\n",
    "        self.last_speed_calculation_time = -1  # Initialize timestamp\n",
    "\n",
    "        # Track episode progress\n",
    "        self.collision_count = 0\n",
    "        self.steps_since_last_collision = 0\n",
    "        self.max_collisions = 3  # End episode after 3 collisions\n",
    "        self.min_steps_between_collisions = 25  # Minimum steps to consider it a new attempt\n",
    "\n",
    "\n",
    "    def calculateSpeed(self, cx):\n",
    "        if cx == -1:\n",
    "            return self.speed\n",
    "        if self.last_speed_calculation_time==-1:\n",
    "            self.last_speed_calculation_time = time.time()\n",
    "            self.pcx = cx\n",
    "            return self.speed\n",
    "        current_time = time.time()\n",
    "        time_delta = current_time - self.last_speed_calculation_time\n",
    "        if time_delta < 0.05:\n",
    "            return self.speed\n",
    "        self.last_speed_calculation_time = current_time\n",
    "        distance = abs(self.pcx - cx)\n",
    "        currentSpeed = distance / time_delta\n",
    "        currentSpeed = max(currentSpeed, 100)\n",
    "        self.speed = currentSpeed\n",
    "        self.pcx = cx\n",
    "        return currentSpeed\n",
    "\n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0: 'space',\n",
    "            1: 'down',\n",
    "            2: 'no_op',\n",
    "        }\n",
    "        if action != 2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        observation = self.get_observation()\n",
    "        # Get object positions and names\n",
    "        try:\n",
    "            reward, done = self.calculate_reward(self.objects_positions, {0: 'bird', 1: 'cactus', 2: 'restart', 3: 't-rex'})\n",
    "        except Exception as e:\n",
    "            print(\"Error in object detection or reward calculation:\", e)\n",
    "            reward = -10\n",
    "            done = False\n",
    "\n",
    "        info = {}\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "    def calculate_reward(self, filtered_data, names):\n",
    "        \"\"\"Calculate reward based on T-Rex position relative to obstacles\"\"\"\n",
    "        name_to_id = {v: k for k, v in names.items()}\n",
    "\n",
    "        trex_box = None\n",
    "        cactus_box = None\n",
    "        bird_box = None\n",
    "        restart_detected = False\n",
    "\n",
    "        for box in filtered_data:\n",
    "            class_id = int(box[5])\n",
    "            if class_id == name_to_id.get('t-rex'):\n",
    "                trex_box = box\n",
    "            elif class_id == name_to_id.get('cactus'):\n",
    "                cactus_box = box\n",
    "            elif class_id == name_to_id.get('bird'):\n",
    "                bird_box = box\n",
    "            elif class_id == name_to_id.get('restart'):\n",
    "                restart_detected = True\n",
    "\n",
    "        # Handle collision but don't end episode immediately\n",
    "        if restart_detected:\n",
    "            self.pcx = 641\n",
    "            self.speed = 350\n",
    "            self.last_speed_calculation_time = -1\n",
    "            print('ðŸ’€', end=\"\")\n",
    "\n",
    "            # Only count as new collision if enough steps have passed\n",
    "            if self.steps_since_last_collision > self.min_steps_between_collisions:\n",
    "                self.collision_count += 1\n",
    "                print(f\"Collision #{self.collision_count}\", end=\" | \")\n",
    "\n",
    "            self.steps_since_last_collision = 0\n",
    "\n",
    "            # Restart the game automatically\n",
    "            time.sleep(0.3)\n",
    "            monitor_2 = self.cap.monitors[1]\n",
    "            pydirectinput.click(x=monitor_2[\"left\"] + 250, y=monitor_2[\"top\"] + 200)\n",
    "            pydirectinput.press('space')\n",
    "            time.sleep(0.3)\n",
    "\n",
    "            # End episode only after multiple collisions\n",
    "            done = self.collision_count >= self.max_collisions\n",
    "            return -100, done\n",
    "\n",
    "        # Increment steps counter\n",
    "        self.steps_since_last_collision += 1\n",
    "\n",
    "        if trex_box is None:\n",
    "            return 0, False\n",
    "\n",
    "        trex_x1, trex_y1, trex_x2, trex_y2 = [float(x) for x in trex_box[:4]]\n",
    "        trex_center_x = (trex_x1 + trex_x2) / 2\n",
    "\n",
    "        # Base reward for survival\n",
    "        reward = 1.0\n",
    "\n",
    "        # Check cactus interaction\n",
    "        if cactus_box is not None:\n",
    "            cactus_x1, cactus_y1, cactus_x2, cactus_y2 = [float(x) for x in cactus_box[:4]]\n",
    "            distance = cactus_x1 - trex_x2\n",
    "\n",
    "            if distance > 50:\n",
    "                reward += 0.5\n",
    "            elif 0 < distance < 50:\n",
    "                if trex_y2 < cactus_y1:\n",
    "                    print(\"âœ…ðŸŒµ\", end=\" | \")\n",
    "                    reward += 5.0\n",
    "                else:\n",
    "                    reward -= 2.0\n",
    "\n",
    "        # Check bird interaction\n",
    "        if bird_box is not None:\n",
    "            bird_x1, bird_y1, bird_x2, bird_y2 = [float(x) for x in bird_box[:4]]\n",
    "            distance = bird_x1 - trex_x2\n",
    "\n",
    "            if distance > 50:\n",
    "                reward += 0.5\n",
    "            elif 0 < distance < 50:\n",
    "                if trex_y2 > bird_y2 or trex_y1 < bird_y2:\n",
    "                    print(\"âœ…ðŸ¦\", end=\" | \")\n",
    "                    reward += 5.0\n",
    "                else:\n",
    "                    reward -= 2.0\n",
    "\n",
    "        print(\".\", end=\"\")\n",
    "        return reward, False\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        print(f\"\\nðŸ”„ Episode reset (Total collisions: {self.collision_count})\")\n",
    "        # Reset episode tracking variables\n",
    "        self.collision_count = 0\n",
    "        self.steps_since_last_collision = 0\n",
    "        time.sleep(0.25)\n",
    "        monitor_2 = self.cap.monitors[1]\n",
    "        pydirectinput.click(x=monitor_2[\"left\"] + 250, y=monitor_2[\"top\"] + 200)\n",
    "        pydirectinput.press('space')\n",
    "        time.sleep(0.25)\n",
    "        return self.get_observation(), {}\n",
    "\n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))\n",
    "        raw_rgb = raw[:, :, :3].astype(np.uint8)\n",
    "        gray = cv2.cvtColor(raw_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        filtered_data = getObjectPositions(gray)\n",
    "        self.objects_positions = filtered_data\n",
    "        formated_observation = format_onservation(filtered_data)\n",
    "        formated_observation[3] = self.calculateSpeed(formated_observation[0])\n",
    "        # print(f'[{int(formated_observation[0])},{int(formated_observation[3])}]', end=\"  \")\n",
    "        return formated_observation\n"
   ],
   "id": "db3ee1833da5e51b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:32:31.383851Z",
     "start_time": "2025-11-13T19:32:31.345415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = WebGame()\n",
    "env.get_observation()\n",
    "# cactus-x1, bird-x1, bird-y1"
   ],
   "id": "346df2f98280aee4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     139.83,          -1,          -1,         350], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:31:29.904190Z",
     "start_time": "2025-11-13T19:29:40.788886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for episodes in range(3):\n",
    "    obs = env.reset(1)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        obs, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "        total_reward += reward\n",
    "    print(\"total reward:\", total_reward, \". for episodes:\", episodes)"
   ],
   "id": "f1e81f210d46032f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      "[-1,350]  [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[605,100]  .[484,367]  .[369,351]  .[244,378]  .[132,342]  .[122,342]  .[552,1220]  .[552,1220]  .[552,100]  .[552,100]  .[552,100]  .[552,100]  ðŸ’€Collision #1 | [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[569,350]  .[558,350]  .[440,360]  .[316,379]  .[200,353]  âœ…ðŸŒµ | .[102,300]  .[102,100]  .[102,100]  .[102,100]  .[102,100]  ðŸ’€Collision #2 | [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[608,350]  .[487,357]  .[364,369]  .[240,382]  .[155,256]  .[155,256]  .[155,256]  .[155,100]  .[155,100]  .[155,100]  .[155,100]  .[155,100]  .[155,100]  .[155,100]  .[155,100]  ðŸ’€Collision #3 | total reward: -202.5 . for episodes: 0\n",
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "[-1,350]  [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[598,350]  .[481,357]  .[361,374]  .[356,374]  .[239,353]  .[122,349]  .[110,349]  .[578,1262]  .[451,382]  .[440,382]  .[316,374]  .[186,389]  âœ…ðŸŒµ | .[128,181]  .[128,100]  .[128,100]  .[128,100]  .[128,100]  ðŸ’€Collision #1 | [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[611,350]  .[491,362]  .[366,374]  .[247,355]  .[155,278]  .[155,278]  .[155,100]  .[155,100]  .[155,100]  .[155,100]  ðŸ’€[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[610,350]  .[486,378]  .[371,348]  .[251,371]  .[244,371]  .[156,271]  .[156,271]  .[156,271]  .[156,100]  .[156,100]  .[156,100]  .[156,100]  ðŸ’€[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[597,350]  .[587,350]  .[469,347]  .[456,347]  .[338,376]  .[218,366]  âœ…ðŸŒµ | .[101,360]  .[101,100]  .[101,100]  .[98,100]  ðŸ’€[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[597,350]  .[478,364]  .[359,357]  .[241,357]  .[139,311]  .[139,100]  .[139,100]  .[139,100]  ðŸ’€[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[623,350]  .[503,353]  .[384,358]  .[261,352]  .[97,510]  .[97,100]  .[97,100]  .[97,100]  .[97,100]  ðŸ’€[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[594,350]  .[584,350]  .[468,363]  .[460,363]  .[346,355]  .[339,355]  .[219,367]  .[212,367]  .[102,342]  .[105,342]  .[-1,342]  .[-1,342]  .[574,692]  .[452,374]  .[443,374]  .[308,406]  .[181,379]  .[-1,379]  .[630,674]  .[458,510]  .[439,510]  .[257,568]  .[139,366]  .[139,366]  .[139,100]  .[139,100]  .[139,100]  .[139,100]  ðŸ’€Collision #2 | [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[565,350]  .[448,354]  .[330,366]  .[321,366]  .[311,366]  .[197,366]  .[105,275]  .[-1,275]  .[579,713]  .[456,379]  .[328,390]  .[198,392]  .[168,100]  .[168,100]  .[168,100]  .[168,100]  ðŸ’€Collision #3 | total reward: -555.5 . for episodes: 1\n",
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "[-1,350]  [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[600,350]  .[484,356]  .[473,356]  .[352,376]  .[232,367]  .[136,291]  .[136,100]  .[136,100]  .[136,100]  .[136,100]  .[137,100]  ðŸ’€[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[604,350]  .[486,363]  .[368,360]  .[247,356]  .[103,438]  .[103,438]  .[103,100]  .[103,100]  .[103,100]  .[103,100]  .[99,100]  ðŸ’€[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  [-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[-1,350]  .[594,350]  .[478,346]  .[355,367]  .[346,367]  .[223,369]  .[216,369]  .[207,369]  .[199,326]  .[190,326]  .[176,424]  .[104,221]  .[-1,221]  .[-1,221]  .[499,401]  .[486,401]  ."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m total_reward = \u001B[32m0\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m     obs, reward, done, truncated, info = \u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43maction_space\u001B[49m\u001B[43m.\u001B[49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m     total_reward += reward\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mtotal reward:\u001B[39m\u001B[33m\"\u001B[39m, total_reward, \u001B[33m\"\u001B[39m\u001B[33m. for episodes:\u001B[39m\u001B[33m\"\u001B[39m, episodes)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 66\u001B[39m, in \u001B[36mWebGame.step\u001B[39m\u001B[34m(self, action)\u001B[39m\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m action != \u001B[32m2\u001B[39m:\n\u001B[32m     64\u001B[39m     pydirectinput.press(action_map[action])\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m observation = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_observation\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# Get object positions and names\u001B[39;00m\n\u001B[32m     68\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 182\u001B[39m, in \u001B[36mWebGame.get_observation\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    180\u001B[39m raw_rgb = raw[:, :, :\u001B[32m3\u001B[39m].astype(np.uint8)\n\u001B[32m    181\u001B[39m gray = cv2.cvtColor(raw_rgb, cv2.COLOR_RGB2GRAY)\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m filtered_data = \u001B[43mgetObjectPositions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgray\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    183\u001B[39m \u001B[38;5;28mself\u001B[39m.objects_positions = filtered_data\n\u001B[32m    184\u001B[39m formated_observation = format_onservation(filtered_data)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 9\u001B[39m, in \u001B[36mgetObjectPositions\u001B[39m\u001B[34m(observation)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgetObjectPositions\u001B[39m(observation):\n\u001B[32m      8\u001B[39m         observation = cv2.cvtColor(observation, cv2.COLOR_GRAY2RGB)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m         results = \u001B[43myolo_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m=\u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.25\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimgsz\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m640\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m         result = results[\u001B[32m0\u001B[39m]\n\u001B[32m     11\u001B[39m         boxes = result.boxes\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:540\u001B[39m, in \u001B[36mModel.predict\u001B[39m\u001B[34m(self, source, stream, predictor, **kwargs)\u001B[39m\n\u001B[32m    538\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prompts \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.predictor, \u001B[33m\"\u001B[39m\u001B[33mset_prompts\u001B[39m\u001B[33m\"\u001B[39m):  \u001B[38;5;66;03m# for SAM-type models\u001B[39;00m\n\u001B[32m    539\u001B[39m     \u001B[38;5;28mself\u001B[39m.predictor.set_prompts(prompts)\n\u001B[32m--> \u001B[39m\u001B[32m540\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.predictor.predict_cli(source=source) \u001B[38;5;28;01mif\u001B[39;00m is_cli \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredictor\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m=\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:225\u001B[39m, in \u001B[36mBasePredictor.__call__\u001B[39m\u001B[34m(self, source, model, stream, *args, **kwargs)\u001B[39m\n\u001B[32m    223\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.stream_inference(source, model, *args, **kwargs)\n\u001B[32m    224\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m225\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstream_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:38\u001B[39m, in \u001B[36m_wrap_generator.<locals>.generator_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     35\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     36\u001B[39m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[32m     37\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m         response = \u001B[43mgen\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     40\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m     41\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     42\u001B[39m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:328\u001B[39m, in \u001B[36mBasePredictor.stream_inference\u001B[39m\u001B[34m(self, source, model, *args, **kwargs)\u001B[39m\n\u001B[32m    326\u001B[39m \u001B[38;5;66;03m# Inference\u001B[39;00m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m profilers[\u001B[32m1\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m328\u001B[39m     preds = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    329\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.embed:\n\u001B[32m    330\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m [preds] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(preds, torch.Tensor) \u001B[38;5;28;01melse\u001B[39;00m preds  \u001B[38;5;66;03m# yield embedding tensors\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:182\u001B[39m, in \u001B[36mBasePredictor.inference\u001B[39m\u001B[34m(self, im, *args, **kwargs)\u001B[39m\n\u001B[32m    176\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001B[39;00m\n\u001B[32m    177\u001B[39m visualize = (\n\u001B[32m    178\u001B[39m     increment_path(\u001B[38;5;28mself\u001B[39m.save_dir / Path(\u001B[38;5;28mself\u001B[39m.batch[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m]).stem, mkdir=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    179\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.visualize \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.source_type.tensor)\n\u001B[32m    180\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    181\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maugment\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43maugment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvisualize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvisualize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membed\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m.\u001B[49m\u001B[43membed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:658\u001B[39m, in \u001B[36mAutoBackend.forward\u001B[39m\u001B[34m(self, im, augment, visualize, embed, **kwargs)\u001B[39m\n\u001B[32m    656\u001B[39m \u001B[38;5;66;03m# PyTorch\u001B[39;00m\n\u001B[32m    657\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pt \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.nn_module:\n\u001B[32m--> \u001B[39m\u001B[32m658\u001B[39m     y = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maugment\u001B[49m\u001B[43m=\u001B[49m\u001B[43maugment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvisualize\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvisualize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membed\u001B[49m\u001B[43m=\u001B[49m\u001B[43membed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    660\u001B[39m \u001B[38;5;66;03m# TorchScript\u001B[39;00m\n\u001B[32m    661\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.jit:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:137\u001B[39m, in \u001B[36mBaseModel.forward\u001B[39m\u001B[34m(self, x, *args, **kwargs)\u001B[39m\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):  \u001B[38;5;66;03m# for cases of training and validating while training.\u001B[39;00m\n\u001B[32m    136\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loss(x, *args, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:154\u001B[39m, in \u001B[36mBaseModel.predict\u001B[39m\u001B[34m(self, x, profile, visualize, augment, embed)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m augment:\n\u001B[32m    153\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._predict_augment(x)\n\u001B[32m--> \u001B[39m\u001B[32m154\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_predict_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprofile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvisualize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membed\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:176\u001B[39m, in \u001B[36mBaseModel._predict_once\u001B[39m\u001B[34m(self, x, profile, visualize, embed)\u001B[39m\n\u001B[32m    174\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m profile:\n\u001B[32m    175\u001B[39m     \u001B[38;5;28mself\u001B[39m._profile_one_layer(m, x, dt)\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m x = \u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# run\u001B[39;00m\n\u001B[32m    177\u001B[39m y.append(x \u001B[38;5;28;01mif\u001B[39;00m m.i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.save \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# save output\u001B[39;00m\n\u001B[32m    178\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m visualize:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:306\u001B[39m, in \u001B[36mC2f.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    304\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001B[39;00m\n\u001B[32m    305\u001B[39m y = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m.cv1(x).chunk(\u001B[32m2\u001B[39m, \u001B[32m1\u001B[39m))\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m \u001B[43my\u001B[49m\u001B[43m.\u001B[49m\u001B[43mextend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mm\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cv2(torch.cat(y, \u001B[32m1\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:306\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m    304\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001B[39;00m\n\u001B[32m    305\u001B[39m y = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m.cv1(x).chunk(\u001B[32m2\u001B[39m, \u001B[32m1\u001B[39m))\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m y.extend(\u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.m)\n\u001B[32m    307\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cv2(torch.cat(y, \u001B[32m1\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:340\u001B[39m, in \u001B[36mC3.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    338\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch.Tensor) -> torch.Tensor:\n\u001B[32m    339\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Forward pass through the CSP bottleneck with 3 convolutions.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m340\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcv3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:89\u001B[39m, in \u001B[36mConv.forward_fuse\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward_fuse\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     81\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Apply convolution and activation without batch normalization.\u001B[39;00m\n\u001B[32m     82\u001B[39m \n\u001B[32m     83\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     87\u001B[39m \u001B[33;03m        (torch.Tensor): Output tensor.\u001B[39;00m\n\u001B[32m     88\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mact\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:473\u001B[39m, in \u001B[36mSiLU.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m    470\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    471\u001B[39m \u001B[33;03m    Runs the forward pass.\u001B[39;00m\n\u001B[32m    472\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m473\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43msilu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2370\u001B[39m, in \u001B[36msilu\u001B[39m\u001B[34m(input, inplace)\u001B[39m\n\u001B[32m   2368\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(silu, (\u001B[38;5;28minput\u001B[39m,), \u001B[38;5;28minput\u001B[39m, inplace=inplace)\n\u001B[32m   2369\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[32m-> \u001B[39m\u001B[32m2370\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_C\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_nn\u001B[49m\u001B[43m.\u001B[49m\u001B[43msilu_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   2371\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m torch._C._nn.silu(\u001B[38;5;28minput\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:32:34.319312Z",
     "start_time": "2025-11-13T19:32:34.314633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker"
   ],
   "id": "f59c4d127b8a19bc",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:32:40.866577Z",
     "start_time": "2025-11-13T19:32:35.005027Z"
    }
   },
   "cell_type": "code",
   "source": "env_checker.check_env(env)",
   "id": "bd4b13577bc30577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      ".\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      ".........âœ…ðŸŒµ | ."
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:32:46.737279Z",
     "start_time": "2025-11-13T19:32:46.733138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "        return True"
   ],
   "id": "331e1d7200d0b6f0",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:33:16.724243Z",
     "start_time": "2025-11-13T19:33:16.721692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ],
   "id": "30d48cb2bf5982a6",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:33:16.928135Z",
     "start_time": "2025-11-13T19:33:16.925643Z"
    }
   },
   "cell_type": "code",
   "source": "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)",
   "id": "2c05715e7c447c47",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:33:17.124696Z",
     "start_time": "2025-11-13T19:33:17.122143Z"
    }
   },
   "cell_type": "code",
   "source": "from stable_baselines3 import DQN",
   "id": "fad41f9ef99b61b2",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T19:33:19.051554Z",
     "start_time": "2025-11-13T19:33:17.946206Z"
    }
   },
   "cell_type": "code",
   "source": "model = DQN('MlpPolicy', env, tensorboard_log=LOG_DIR, verbose=2, buffer_size=10000, learning_starts=1000)",
   "id": "3a8fc21230c206b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T20:56:34.558591Z",
     "start_time": "2025-11-13T19:38:05.890599Z"
    }
   },
   "cell_type": "code",
   "source": "model.learn(total_timesteps=10000000, callback=callback)",
   "id": "5da3d3aa51d539e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      "Logging to ./logs/DQN_2\n",
      ".........................................ðŸ’€Collision #1 | .........................ðŸ’€....................âœ…ðŸŒµ | ....ðŸ’€....................ðŸ’€.....................ðŸ’€.........................âœ…ðŸŒµ | ....ðŸ’€Collision #2 | .............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "............................âœ…ðŸŒµ | .....ðŸ’€Collision #1 | ..............................................ðŸ’€Collision #2 | ...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................ðŸ’€.......................ðŸ’€.............................................ðŸ’€Collision #1 | ........................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................ðŸ’€...........................ðŸ’€Collision #1 | .....................âœ…ðŸŒµ | .....ðŸ’€Collision #2 | ...................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 142      |\n",
      "|    ep_rew_mean      | -322     |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 569      |\n",
      "----------------------------------\n",
      "...................ðŸ’€............................ðŸ’€Collision #1 | ................................âœ…ðŸŒµ | ......ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..............âœ…ðŸŒµ | .âœ…ðŸŒµ | .......ðŸ’€...................................âœ…ðŸŒµ | ....ðŸ’€Collision #1 | ...........................ðŸ’€Collision #2 | .......................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".............âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | .......ðŸ’€..................................ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...................âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€Collision #1 | .....................ðŸ’€.......................ðŸ’€................................ðŸ’€Collision #2 | .....................âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | -305     |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 1069     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.95     |\n",
      "|    n_updates        | 17       |\n",
      "----------------------------------\n",
      "...................âœ…ðŸŒµ | ......ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | ........................ðŸ’€......................ðŸ’€...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€.......................âœ…ðŸŒµ | .......ðŸ’€Collision #1 | .....................................ðŸ’€Collision #2 | ......................ðŸ’€......................ðŸ’€......................ðŸ’€......................ðŸ’€...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "................................ðŸ’€Collision #1 | .........................ðŸ’€........................ðŸ’€...................âœ…ðŸŒµ | .......ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................ðŸ’€........................ðŸ’€.............................ðŸ’€Collision #1 | .................................ðŸ’€Collision #2 | .............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | -341     |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 462      |\n",
      "|    total_timesteps  | 1697     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.67     |\n",
      "|    n_updates        | 174      |\n",
      "----------------------------------\n",
      "........................ðŸ’€........................ðŸ’€....................ðŸ’€................................ðŸ’€Collision #1 | .......................ðŸ’€.............................ðŸ’€Collision #2 | .................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................ðŸ’€...............................ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | ......................ðŸ’€.......................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...................âœ…ðŸŒµ | ......ðŸ’€......................âœ…ðŸŒµ | ......ðŸ’€Collision #1 | ...................ðŸ’€.......................ðŸ’€.................................ðŸ’€Collision #2 | ....................ðŸ’€......................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...................ðŸ’€.........................ðŸ’€.............................ðŸ’€Collision #1 | .....................................ðŸ’€Collision #2 | ...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 149      |\n",
      "|    ep_rew_mean      | -373     |\n",
      "|    exploration_rate | 0.998    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 657      |\n",
      "|    total_timesteps  | 2387     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 346      |\n",
      "----------------------------------\n",
      ".........................ðŸ’€...................âœ…ðŸŒµ | .....ðŸ’€.............................âœ…ðŸŒµ | ....ðŸ’€Collision #1 | ..............................ðŸ’€Collision #2 | ........................ðŸ’€...................ðŸ’€...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................âœ…ðŸŒµ | ......ðŸ’€.......................ðŸ’€...................âœ…ðŸŒµ | ........ðŸ’€Collision #1 | ...............................ðŸ’€Collision #2 | ................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€.............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................ðŸ’€...............................ðŸ’€Collision #1 | .........................................ðŸ’€Collision #2 | ......................ðŸ’€...............................âœ…ðŸŒµ | ........ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€..............................ðŸ’€Collision #1 | ........................ðŸ’€.........................ðŸ’€....................âœ…ðŸŒµ | .......ðŸ’€Collision #2 | ..................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 154      |\n",
      "|    ep_rew_mean      | -381     |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 838      |\n",
      "|    total_timesteps  | 3070     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.04     |\n",
      "|    n_updates        | 517      |\n",
      "----------------------------------\n",
      "..........................ðŸ’€Collision #1 | .........................ðŸ’€..........................ðŸ’€Collision #2 | .....................ðŸ’€...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................âœ…ðŸŒµ | ....ðŸ’€..................ðŸ’€......................ðŸ’€.........................ðŸ’€............................ðŸ’€Collision #1 | .............................ðŸ’€Collision #2 | .....................ðŸ’€.....................âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€......................ðŸ’€....................................ðŸ’€Collision #1 | .................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | .........ðŸ’€Collision #2 | ..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€....................âœ…ðŸŒµ | .....ðŸ’€...............................ðŸ’€Collision #1 | ........................ðŸ’€..........................ðŸ’€Collision #2 | .......................ðŸ’€......................âœ…ðŸŒµ | ....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 155      |\n",
      "|    ep_rew_mean      | -393     |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1021     |\n",
      "|    total_timesteps  | 3725     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 681      |\n",
      "----------------------------------\n",
      "..............................âœ…ðŸŒµ | .âœ…ðŸŒµ | ........ðŸ’€Collision #1 | ...........................âœ…ðŸŒµ | ....ðŸ’€Collision #2 | ......................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...........................ðŸ’€Collision #1 | .......................ðŸ’€............................ðŸ’€Collision #2 | .........................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................âœ…ðŸŒµ | .....ðŸ’€..................âœ…ðŸŒµ | ....ðŸ’€............................ðŸ’€Collision #1 | ..................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | .......ðŸ’€Collision #2 | ..................âœ…ðŸŒµ | ........ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "................ðŸ’€..............................ðŸ’€Collision #1 | ......................âœ…ðŸŒµ | ....ðŸ’€Collision #2 | ........................ðŸ’€.................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 152      |\n",
      "|    ep_rew_mean      | -383     |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1163     |\n",
      "|    total_timesteps  | 4246     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.28     |\n",
      "|    n_updates        | 811      |\n",
      "----------------------------------\n",
      "...................ðŸ’€.....................ðŸ’€................................ðŸ’€Collision #1 | ...........................ðŸ’€Collision #2 | ....................âœ…ðŸŒµ | ....ðŸ’€.....................âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "............................ðŸ’€Collision #1 | .........................ðŸ’€.........................................ðŸ’€Collision #2 | ....................ðŸ’€........................ðŸ’€..................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..........................ðŸ’€Collision #1 | .................................ðŸ’€Collision #2 | ...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................ðŸ’€......................âœ…ðŸŒµ | ......ðŸ’€Collision #1 | ......................ðŸ’€.....................âœ…ðŸŒµ | ....ðŸ’€.......................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€Collision #2 | ....................âœ…ðŸŒµ | .....ðŸ’€................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 152      |\n",
      "|    ep_rew_mean      | -385     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1333     |\n",
      "|    total_timesteps  | 4862     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.97     |\n",
      "|    n_updates        | 965      |\n",
      "----------------------------------\n",
      ".........................ðŸ’€.........................ðŸ’€...............................ðŸ’€Collision #1 | .................................ðŸ’€Collision #2 | .............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..........................ðŸ’€Collision #1 | ......................ðŸ’€......................âœ…ðŸŒµ | ....ðŸ’€Collision #2 | ........................ðŸ’€......................âœ…ðŸŒµ | ......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................ðŸ’€.......................................ðŸ’€Collision #1 | .........................ðŸ’€.......................................ðŸ’€Collision #2 | .............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "......................ðŸ’€...........................ðŸ’€Collision #1 | .........................ðŸ’€............................ðŸ’€Collision #2 | ...................âœ…ðŸŒµ | ......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 151      |\n",
      "|    ep_rew_mean      | -382     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1484     |\n",
      "|    total_timesteps  | 5429     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 15.7     |\n",
      "|    n_updates        | 1107     |\n",
      "----------------------------------\n",
      "......................ðŸ’€..................âœ…ðŸŒµ | .....ðŸ’€....................âœ…ðŸŒµ | .âœ…ðŸŒµ | ....ðŸ’€.......................ðŸ’€............................ðŸ’€Collision #1 | ......................ðŸ’€......................âœ…ðŸŒµ | .....ðŸ’€Collision #2 | ........................ðŸ’€.......................ðŸ’€........................ðŸ’€...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".........................ðŸ’€....................ðŸ’€..........................âœ…ðŸŒµ | ....ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | .....................âœ…ðŸŒµ | .âœ…ðŸŒµ | .......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€..................................ðŸ’€Collision #1 | ..................âœ…ðŸŒµ | ......ðŸ’€...................âœ…ðŸŒµ | ......ðŸ’€................................ðŸ’€Collision #2 | ....................âœ…ðŸŒµ | .......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................ðŸ’€....................................ðŸ’€Collision #1 | ......................ðŸ’€...................................ðŸ’€Collision #2 | ..............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 154      |\n",
      "|    ep_rew_mean      | -391     |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1688     |\n",
      "|    total_timesteps  | 6170     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.485    |\n",
      "|    n_updates        | 1292     |\n",
      "----------------------------------\n",
      "......................ðŸ’€.....................âœ…ðŸŒµ | ....ðŸ’€....................âœ…ðŸŒµ | .......ðŸ’€Collision #1 | ....................âœ…ðŸŒµ | .......ðŸ’€Collision #2 | .........................ðŸ’€......................âœ…ðŸŒµ | .âœ…ðŸŒµ | ....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..........................ðŸ’€Collision #1 | .......................âœ…ðŸŒµ | .....ðŸ’€Collision #2 | .......................ðŸ’€..............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".......................ðŸ’€................................ðŸ’€Collision #1 | ..................................ðŸ’€Collision #2 | ......................ðŸ’€.........................ðŸ’€..................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "........................ðŸ’€.......................ðŸ’€.................................ðŸ’€Collision #1 | .............................ðŸ’€Collision #2 | ..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 154      |\n",
      "|    ep_rew_mean      | -389     |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1850     |\n",
      "|    total_timesteps  | 6759     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.852    |\n",
      "|    n_updates        | 1439     |\n",
      "----------------------------------\n",
      "....................ðŸ’€..................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | .....ðŸ’€................................âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€Collision #1 | ...................................ðŸ’€Collision #2 | ..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................ðŸ’€..............................ðŸ’€Collision #1 | ..................................ðŸ’€Collision #2 | .........................ðŸ’€.......................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".........................ðŸ’€......................ðŸ’€.....................ðŸ’€..........................ðŸ’€Collision #1 | ...................âœ…ðŸŒµ | .âœ…ðŸŒµ | ....ðŸ’€............................ðŸ’€Collision #2 | ...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€....................âœ…ðŸŒµ | .......ðŸ’€Collision #1 | ................................ðŸ’€Collision #2 | .....................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 153      |\n",
      "|    ep_rew_mean      | -388     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 2017     |\n",
      "|    total_timesteps  | 7365     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.04     |\n",
      "|    n_updates        | 1591     |\n",
      "----------------------------------\n",
      "...............................ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | ......................âœ…ðŸŒµ | .âœ…ðŸŒµ | ....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...................âœ…ðŸŒµ | .....ðŸ’€........................ðŸ’€.............................ðŸ’€Collision #1 | .....................âœ…ðŸŒµ | .âœ…ðŸŒµ | .....ðŸ’€Collision #2 | .....................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..........................ðŸ’€Collision #1 | ..............................ðŸ’€Collision #2 | ..............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "................âœ…ðŸŒµ | .........ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | .......................ðŸ’€......................ðŸ’€.............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 150      |\n",
      "|    ep_rew_mean      | -380     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 2140     |\n",
      "|    total_timesteps  | 7820     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.85     |\n",
      "|    n_updates        | 1704     |\n",
      "----------------------------------\n",
      "..........................ðŸ’€Collision #1 | ......................ðŸ’€.........................ðŸ’€................................ðŸ’€Collision #2 | ......................ðŸ’€.................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...................ðŸ’€....................âœ…ðŸŒµ | .....ðŸ’€.............................ðŸ’€Collision #1 | .................................ðŸ’€Collision #2 | ......................ðŸ’€........................âœ…ðŸŒµ | ....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...............âœ…ðŸŒµ | .....ðŸ’€.......................ðŸ’€.....................ðŸ’€............................ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | ....................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "......................ðŸ’€..........................ðŸ’€Collision #1 | ...........................ðŸ’€Collision #2 | .......................ðŸ’€.................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 151      |\n",
      "|    ep_rew_mean      | -382     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 2310     |\n",
      "|    total_timesteps  | 8447     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.07     |\n",
      "|    n_updates        | 1861     |\n",
      "----------------------------------\n",
      "....................ðŸ’€......................................ðŸ’€Collision #1 | .........................ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..........................ðŸ’€Collision #1 | ....................âœ…ðŸŒµ | .........ðŸ’€Collision #2 | ......................ðŸ’€...................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................ðŸ’€......................................ðŸ’€Collision #1 | ................................ðŸ’€Collision #2 | ....................âœ…ðŸŒµ | .âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".........................ðŸ’€.........................ðŸ’€......................ðŸ’€.............................ðŸ’€Collision #1 | ........................ðŸ’€..................................âœ…ðŸŒµ | ......ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 150      |\n",
      "|    ep_rew_mean      | -380     |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 2467     |\n",
      "|    total_timesteps  | 9009     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.72     |\n",
      "|    n_updates        | 2002     |\n",
      "----------------------------------\n",
      "..........................ðŸ’€Collision #1 | .............................ðŸ’€Collision #2 | .......................ðŸ’€.............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................ðŸ’€..............................ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | .............................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | ........ðŸ’€Collision #1 | .......................................ðŸ’€Collision #2 | ...................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".............âœ…ðŸŒµ | ....ðŸ’€..............................ðŸ’€Collision #1 | .............................ðŸ’€Collision #2 | ......................âœ…ðŸŒµ | .âœ…ðŸŒµ | .......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | -372     |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 2586     |\n",
      "|    total_timesteps  | 9457     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.21     |\n",
      "|    n_updates        | 2114     |\n",
      "----------------------------------\n",
      "......................ðŸ’€.........................ðŸ’€.........................ðŸ’€..........................ðŸ’€Collision #1 | ..................................ðŸ’€Collision #2 | .....................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...................ðŸ’€..........................ðŸ’€Collision #1 | ........................ðŸ’€........................âœ…ðŸŒµ | .....ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................âœ…ðŸŒµ | .....ðŸ’€.....................................ðŸ’€Collision #1 | ........................ðŸ’€............................ðŸ’€Collision #2 | ..............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "......................ðŸ’€.........................âœ…ðŸŒµ | .....ðŸ’€Collision #1 | ...............................ðŸ’€Collision #2 | .......................ðŸ’€............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | -373     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 2748     |\n",
      "|    total_timesteps  | 10050    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.53     |\n",
      "|    n_updates        | 2262     |\n",
      "----------------------------------\n",
      "...............âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€...........................âœ…ðŸŒµ | .....ðŸ’€Collision #1 | .................ðŸ’€........................................ðŸ’€Collision #2 | .........................âœ…ðŸŒµ | ......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................ðŸ’€....................âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | .....ðŸ’€Collision #1 | ......................ðŸ’€............................ðŸ’€Collision #2 | .................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...............âœ…ðŸŒµ | ....ðŸ’€.......................ðŸ’€........................................ðŸ’€Collision #1 | .......................ðŸ’€.......................ðŸ’€...............................ðŸ’€Collision #2 | ....................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................ðŸ’€......................ðŸ’€...............................ðŸ’€Collision #1 | .....................ðŸ’€.........................ðŸ’€Collision #2 | ..............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 149      |\n",
      "|    ep_rew_mean      | -374     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 2920     |\n",
      "|    total_timesteps  | 10694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.78     |\n",
      "|    n_updates        | 2423     |\n",
      "----------------------------------\n",
      "................................ðŸ’€Collision #1 | .........................ðŸ’€...............................ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".......................ðŸ’€.....................ðŸ’€...........................ðŸ’€Collision #1 | ........................ðŸ’€....................................ðŸ’€Collision #2 | ...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................ðŸ’€.............................ðŸ’€Collision #1 | .............................ðŸ’€Collision #2 | ...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€...............................ðŸ’€Collision #1 | .....................âœ…ðŸŒµ | .........ðŸ’€Collision #2 | ......................âœ…ðŸŒµ | ....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | -371     |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 3054     |\n",
      "|    total_timesteps  | 11202    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 10.9     |\n",
      "|    n_updates        | 2550     |\n",
      "----------------------------------\n",
      "..............................ðŸ’€Collision #1 | ...................âœ…ðŸŒµ | .......ðŸ’€Collision #2 | ........................ðŸ’€.....................ðŸ’€........................ðŸ’€.....................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".........................ðŸ’€.........................ðŸ’€Collision #1 | ..........................âœ…ðŸŒµ | .......ðŸ’€Collision #2 | ........................ðŸ’€.........................ðŸ’€.........................ðŸ’€.............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................ðŸ’€................................âœ…ðŸŒµ | ......ðŸ’€Collision #1 | ....................âœ…ðŸŒµ | ....ðŸ’€.............................ðŸ’€Collision #2 | ..........................âœ…ðŸŒµ | ......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "......................ðŸ’€......................ðŸ’€.............................ðŸ’€Collision #1 | .................................ðŸ’€Collision #2 | .....................âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | -374     |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 3236     |\n",
      "|    total_timesteps  | 11862    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.95     |\n",
      "|    n_updates        | 2715     |\n",
      "----------------------------------\n",
      "...................ðŸ’€............................ðŸ’€Collision #1 | ........................................ðŸ’€Collision #2 | ................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".............................ðŸ’€Collision #1 | ........................ðŸ’€.....................ðŸ’€.........................ðŸ’€..............................ðŸ’€Collision #2 | ....................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "....................âœ…ðŸŒµ | ........ðŸ’€Collision #1 | .........................ðŸ’€............................âœ…ðŸŒµ | .âœ…ðŸŒµ | ....ðŸ’€Collision #2 | ..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...............âœ…ðŸŒµ | ......ðŸ’€...........................ðŸ’€Collision #1 | ......................ðŸ’€............................ðŸ’€Collision #2 | ...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | -372     |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 3381     |\n",
      "|    total_timesteps  | 12410    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 2852     |\n",
      "----------------------------------\n",
      ".....................âœ…ðŸŒµ | .......ðŸ’€Collision #1 | ..............................ðŸ’€Collision #2 | ......................ðŸ’€...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€...........................ðŸ’€Collision #1 | ............................ðŸ’€Collision #2 | ......................ðŸ’€........................ðŸ’€...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................ðŸ’€...........................ðŸ’€Collision #1 | .................âœ…ðŸŒµ | .....ðŸ’€...........................ðŸ’€Collision #2 | .................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................ðŸ’€....................................ðŸ’€Collision #1 | .............................ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | -370     |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 3525     |\n",
      "|    total_timesteps  | 12925    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 13.3     |\n",
      "|    n_updates        | 2981     |\n",
      "----------------------------------\n",
      ".......................âœ…ðŸŒµ | ........ðŸ’€Collision #1 | ........................ðŸ’€.....................ðŸ’€.....................ðŸ’€.......................................âœ…ðŸŒµ | .........ðŸ’€Collision #2 | ......................ðŸ’€...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................âœ…ðŸŒµ | ....ðŸ’€.......................ðŸ’€..............................ðŸ’€Collision #1 | .........................ðŸ’€Collision #2 | ..............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€....................âœ…ðŸŒµ | .......ðŸ’€Collision #1 | ............................ðŸ’€Collision #2 | ...................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...............âœ…ðŸŒµ | .âœ…ðŸŒµ | .âœ…ðŸŒµ | ....ðŸ’€...............................ðŸ’€Collision #1 | ..............................ðŸ’€Collision #2 | .....................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | -370     |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 3686     |\n",
      "|    total_timesteps  | 13516    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.64     |\n",
      "|    n_updates        | 3128     |\n",
      "----------------------------------\n",
      "............................ðŸ’€Collision #1 | .................................ðŸ’€Collision #2 | .....................ðŸ’€............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".........................................ðŸ’€Collision #1 | .....................âœ…ðŸŒµ | ......ðŸ’€Collision #2 | .....................âœ…ðŸŒµ | ..........ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".........................ðŸ’€...................âœ…ðŸŒµ | ........ðŸ’€Collision #1 | .......................ðŸ’€....................ðŸ’€.....................ðŸ’€........................âœ…ðŸŒµ | .....ðŸ’€Collision #2 | ...........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..........................ðŸ’€Collision #1 | ......................................................ðŸ’€Collision #2 | ......................âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 146      |\n",
      "|    ep_rew_mean      | -367     |\n",
      "|    exploration_rate | 0.987    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 3824     |\n",
      "|    total_timesteps  | 14021    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.17     |\n",
      "|    n_updates        | 3255     |\n",
      "----------------------------------\n",
      "...........................ðŸ’€Collision #1 | .................âœ…ðŸŒµ | ........ðŸ’€Collision #2 | ..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".............âœ…ðŸŒµ | .....ðŸ’€.....................ðŸ’€....................................ðŸ’€Collision #1 | ...........................ðŸ’€Collision #2 | ..................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".......................ðŸ’€...................âœ…ðŸŒµ | .....ðŸ’€.....................âœ…ðŸŒµ | .....ðŸ’€Collision #1 | ......................ðŸ’€....................................ðŸ’€Collision #2 | .....................ðŸ’€....................ðŸ’€............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "............................ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | ..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 145      |\n",
      "|    ep_rew_mean      | -366     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 3971     |\n",
      "|    total_timesteps  | 14541    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 16.2     |\n",
      "|    n_updates        | 3385     |\n",
      "----------------------------------\n",
      ".....................ðŸ’€..........................âœ…ðŸŒµ | ....ðŸ’€Collision #1 | ......................ðŸ’€.......................ðŸ’€........................ðŸ’€.................................ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€........................ðŸ’€.........................ðŸ’€Collision #1 | ...................ðŸ’€...................................ðŸ’€Collision #2 | .........................ðŸ’€.............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "............................ðŸ’€Collision #1 | ...................................ðŸ’€Collision #2 | ...............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".....................ðŸ’€...................ðŸ’€.......................ðŸ’€...........................ðŸ’€Collision #1 | ...................................ðŸ’€Collision #2 | ......................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 146      |\n",
      "|    ep_rew_mean      | -370     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 4157     |\n",
      "|    total_timesteps  | 15198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.38     |\n",
      "|    n_updates        | 3549     |\n",
      "----------------------------------\n",
      ".............................ðŸ’€Collision #1 | ....................âœ…ðŸŒµ | ........ðŸ’€Collision #2 | .......................ðŸ’€......................âœ…ðŸŒµ | .âœ…ðŸŒµ | .........ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "................................ðŸ’€Collision #1 | ..........................ðŸ’€Collision #2 | .......................ðŸ’€.......................ðŸ’€.........................ðŸ’€................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................................ðŸ’€Collision #1 | .....................ðŸ’€......................ðŸ’€........................ðŸ’€..............................ðŸ’€Collision #2 | .............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "...................ðŸ’€........................ðŸ’€....................................ðŸ’€Collision #1 | ........................ðŸ’€....................................ðŸ’€Collision #2 | ........................ðŸ’€......................ðŸ’€..........................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | -376     |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 4338     |\n",
      "|    total_timesteps  | 15868    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 3716     |\n",
      "----------------------------------\n",
      "........................ðŸ’€...................âœ…ðŸŒµ | ..........ðŸ’€Collision #1 | .......................ðŸ’€.........................ðŸ’€........................ðŸ’€.......................ðŸ’€................................ðŸ’€Collision #2 | .........................ðŸ’€..................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "......................ðŸ’€........................ðŸ’€...........................ðŸ’€Collision #1 | ..................................ðŸ’€Collision #2 | .......................âœ…ðŸŒµ | .âœ…ðŸŒµ | ......ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".......................ðŸ’€............................ðŸ’€Collision #1 | ............................ðŸ’€Collision #2 | .................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "............................ðŸ’€Collision #1 | ...........................âœ…ðŸŒµ | .....ðŸ’€Collision #2 | .......................âœ…ðŸŒµ | .âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | -374     |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 4495     |\n",
      "|    total_timesteps  | 16467    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.96     |\n",
      "|    n_updates        | 3866     |\n",
      "----------------------------------\n",
      "..................................ðŸ’€Collision #1 | ........................................ðŸ’€Collision #2 | ...................âœ…ðŸŒµ | .âœ…ðŸŒµ | ....ðŸ’€...................................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..............âœ…ðŸŒµ | ......ðŸ’€..............................ðŸ’€Collision #1 | ..............................ðŸ’€Collision #2 | ............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      ".................ðŸ’€.......................âœ…ðŸŒµ | ........ðŸ’€Collision #1 | ......................ðŸ’€.....................ðŸ’€..........................ðŸ’€Collision #2 | .........................ðŸ’€........................ðŸ’€..............................ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "..................ðŸ’€........................ðŸ’€......................ðŸ’€......................................ðŸ’€Collision #1 | ........................ðŸ’€..........................ðŸ’€Collision #2 | ....................âœ…ðŸŒµ | .âœ…ðŸŒµ | .....ðŸ’€Collision #3 | \n",
      "ðŸ”„ Episode reset (Total collisions: 3)\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | -371     |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 4670     |\n",
      "|    total_timesteps  | 17107    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.36     |\n",
      "|    n_updates        | 4026     |\n",
      "----------------------------------\n",
      ".................âœ…ðŸŒµ | ....ðŸ’€..........................ðŸ’€Collision #1 | ..................âœ…ðŸŒµ | .......ðŸ’€.......................ðŸ’€....................ðŸ’€............"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[49]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10000000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:272\u001B[39m, in \u001B[36mDQN.learn\u001B[39m\u001B[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[39m\n\u001B[32m    263\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlearn\u001B[39m(\n\u001B[32m    264\u001B[39m     \u001B[38;5;28mself\u001B[39m: SelfDQN,\n\u001B[32m    265\u001B[39m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    270\u001B[39m     progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    271\u001B[39m ) -> SelfDQN:\n\u001B[32m--> \u001B[39m\u001B[32m272\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    275\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    276\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    277\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    279\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:335\u001B[39m, in \u001B[36mOffPolicyAlgorithm.learn\u001B[39m\u001B[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[39m\n\u001B[32m    332\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.train_freq, TrainFreq)  \u001B[38;5;66;03m# check done in _setup_learn()\u001B[39;00m\n\u001B[32m    334\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m.num_timesteps < total_timesteps:\n\u001B[32m--> \u001B[39m\u001B[32m335\u001B[39m     rollout = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    337\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_freq\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    338\u001B[39m \u001B[43m        \u001B[49m\u001B[43maction_noise\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maction_noise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    339\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    340\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlearning_starts\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlearning_starts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    342\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    343\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    345\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m rollout.continue_training:\n\u001B[32m    346\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:567\u001B[39m, in \u001B[36mOffPolicyAlgorithm.collect_rollouts\u001B[39m\u001B[34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001B[39m\n\u001B[32m    564\u001B[39m actions, buffer_actions = \u001B[38;5;28mself\u001B[39m._sample_action(learning_starts, action_noise, env.num_envs)\n\u001B[32m    566\u001B[39m \u001B[38;5;66;03m# Rescale and perform action\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m567\u001B[39m new_obs, rewards, dones, infos = \u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    569\u001B[39m \u001B[38;5;28mself\u001B[39m.num_timesteps += env.num_envs\n\u001B[32m    570\u001B[39m num_collected_steps += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:222\u001B[39m, in \u001B[36mVecEnv.step\u001B[39m\u001B[34m(self, actions)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    216\u001B[39m \u001B[33;03mStep the environments with the given action\u001B[39;00m\n\u001B[32m    217\u001B[39m \n\u001B[32m    218\u001B[39m \u001B[33;03m:param actions: the action\u001B[39;00m\n\u001B[32m    219\u001B[39m \u001B[33;03m:return: observation, reward, done, information\u001B[39;00m\n\u001B[32m    220\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    221\u001B[39m \u001B[38;5;28mself\u001B[39m.step_async(actions)\n\u001B[32m--> \u001B[39m\u001B[32m222\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:59\u001B[39m, in \u001B[36mDummyVecEnv.step_wait\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mstep_wait\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> VecEnvStepReturn:\n\u001B[32m     57\u001B[39m     \u001B[38;5;66;03m# Avoid circular imports\u001B[39;00m\n\u001B[32m     58\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m env_idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.num_envs):\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m         obs, \u001B[38;5;28mself\u001B[39m.buf_rews[env_idx], terminated, truncated, \u001B[38;5;28mself\u001B[39m.buf_infos[env_idx] = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43menvs\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[assignment]\u001B[39;49;00m\n\u001B[32m     60\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mactions\u001B[49m\u001B[43m[\u001B[49m\u001B[43menv_idx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     61\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     62\u001B[39m         \u001B[38;5;66;03m# convert to SB3 VecEnv api\u001B[39;00m\n\u001B[32m     63\u001B[39m         \u001B[38;5;28mself\u001B[39m.buf_dones[env_idx] = terminated \u001B[38;5;129;01mor\u001B[39;00m truncated\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001B[39m, in \u001B[36mMonitor.step\u001B[39m\u001B[34m(self, action)\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.needs_reset:\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mTried to step environment that needs reset\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m observation, reward, terminated, truncated, info = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43menv\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     95\u001B[39m \u001B[38;5;28mself\u001B[39m.rewards.append(\u001B[38;5;28mfloat\u001B[39m(reward))\n\u001B[32m     96\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m terminated \u001B[38;5;129;01mor\u001B[39;00m truncated:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[35]\u001B[39m\u001B[32m, line 64\u001B[39m, in \u001B[36mWebGame.step\u001B[39m\u001B[34m(self, action)\u001B[39m\n\u001B[32m     58\u001B[39m action_map = {\n\u001B[32m     59\u001B[39m     \u001B[32m0\u001B[39m: \u001B[33m'\u001B[39m\u001B[33mspace\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     60\u001B[39m     \u001B[32m1\u001B[39m: \u001B[33m'\u001B[39m\u001B[33mdown\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     61\u001B[39m     \u001B[32m2\u001B[39m: \u001B[33m'\u001B[39m\u001B[33mno_op\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     62\u001B[39m }\n\u001B[32m     63\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m action != \u001B[32m2\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m     \u001B[43mpydirectinput\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpress\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43maction\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     66\u001B[39m observation = \u001B[38;5;28mself\u001B[39m.get_observation()\n\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# Get object positions and names\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\pydirectinput\\__init__.py:243\u001B[39m, in \u001B[36m_genericPyDirectInputChecks.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    241\u001B[39m failSafeCheck()\n\u001B[32m    242\u001B[39m returnVal = wrappedFunction(*args, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m243\u001B[39m \u001B[43m_handlePause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfuncArgs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m_pause\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    244\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m returnVal\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\OneDrive\\Desktop\\AI_ML_projects\\projects\\.venv\\Lib\\site-packages\\pydirectinput\\__init__.py:232\u001B[39m, in \u001B[36m_handlePause\u001B[39m\u001B[34m(_pause)\u001B[39m\n\u001B[32m    230\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _pause:\n\u001B[32m    231\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(PAUSE, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(PAUSE, \u001B[38;5;28mfloat\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m232\u001B[39m     \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPAUSE\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # Load the trained model\n",
    "model = DQN.load('train/best_model_20000.zip')\n",
    "# model = DQN.load('yolo_model/best_model_100000.zip')\n",
    "\n",
    "# Test the model\n",
    "episodes = 5\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "\n",
    "    print(f\"Episode {episode + 1} starting...\")\n",
    "\n",
    "    while not done and step_count < 1000:\n",
    "        # Use the trained model to predict actions\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        print(action, end=\" | \")\n",
    "        action = int(action)  # Convert numpy array to scalar\n",
    "\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        step_count += 1\n",
    "\n",
    "        # Add small delay to see the gameplay\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    print(f\"Episode {episode + 1} finished - Total reward: {total_reward}, Steps: {step_count}\")\n"
   ],
   "id": "bb42e171c3225f3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4545e675cc655602",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

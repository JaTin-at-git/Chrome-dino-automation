{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:42:26.275991Z",
     "start_time": "2025-11-13T13:42:25.603158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from coloredlogs.converter import capture\n",
    "# to capture game screen\n",
    "from mss import mss\n",
    "# to provide keystroke inputs to the game\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "# to perform OCR on game screen\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "# to create custom gym environment\n",
    "from gymnasium import Env\n",
    "# to define action and observation space\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "\n",
    "# 0: 'bird'\n",
    "# 1: 'cactus'\n",
    "# 2: 'restart'\n",
    "# 3: 't-rex'"
   ],
   "id": "c9c51797646fb6da",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T13:42:28.475285Z",
     "start_time": "2025-11-13T13:42:26.927216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# code to detect the objects in image\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "yolo_model = YOLO(\"yolo_model/best.pt\")\n",
    "\n",
    "def getObjectPositions(observation):\n",
    "        observation = cv2.cvtColor(observation, cv2.COLOR_GRAY2RGB)\n",
    "        results = yolo_model.predict(source=observation, conf=0.25, imgsz=640, verbose=False)\n",
    "        result = results[0]\n",
    "        boxes = result.boxes\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            return boxes.data\n",
    "\n",
    "        # Group boxes by class and find leftmost for each class\n",
    "        class_leftmost = {}\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            class_id = int(box.cls)\n",
    "            x1 = float(box.xyxy[0][0])  # leftmost x coordinate\n",
    "\n",
    "            # Keep the box with smallest x1 (leftmost) for each class\n",
    "            if class_id not in class_leftmost or x1 < class_leftmost[class_id]['x1']:\n",
    "                class_leftmost[class_id] = {'index': i, 'x1': x1}\n",
    "\n",
    "        # Extract the indices of leftmost boxes for each class\n",
    "        leftmost_indices = [info['index'] for info in class_leftmost.values()]\n",
    "\n",
    "        # Return only the leftmost boxes data\n",
    "        filtered_data = boxes.data[leftmost_indices]\n",
    "        return filtered_data\n"
   ],
   "id": "e26f9d63c75d9e7a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:00:16.665571Z",
     "start_time": "2025-11-13T14:00:16.662683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_onservation(filtered_data):\n",
    "    obs = np.array([-1, -1, -1], dtype=np.float32)\n",
    "    # {0: 'bird', 1: 'cactus', 2: 'restart', 3: 't-rex'}\n",
    "    #cactus-x1, bird-x1, bird-y1\n",
    "    for box in filtered_data:\n",
    "        if int(box[5]) == 1:  # cactus\n",
    "            obs[0] = box[0]  # x1\n",
    "        elif int(box[5]) == 0:  # bird\n",
    "            obs[1] = box[0]  # x1\n",
    "            obs[2] = box[1]  # y1\n",
    "    return obs"
   ],
   "id": "bdf9e62e40fbd86f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:08:58.911906Z",
     "start_time": "2025-11-13T14:08:58.904107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# creating the environment\n",
    "class WebGame(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([\n",
    "                -1,-1,-1  #cactus-x1, bird-x1, bird-y1\n",
    "            ], dtype=np.float32),\n",
    "            high=np.array([\n",
    "                640, 640, 256\n",
    "            ], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "        # define the extraction parameters for the game\n",
    "        self.cap = mss()\n",
    "        monitor_2 = self.cap.monitors[1]\n",
    "        self.game_location = {\n",
    "            'top': monitor_2[\"top\"] + 150,\n",
    "            'left': monitor_2[\"left\"] + 400,\n",
    "            'width': 640,\n",
    "            'height': 256\n",
    "        }\n",
    "\n",
    "        self.objects_positions = []\n",
    "\n",
    "        # Track episode progress\n",
    "        self.collision_count = 0\n",
    "        self.steps_since_last_collision = 0\n",
    "        self.max_collisions = 3  # End episode after 3 collisions\n",
    "        self.min_steps_between_collisions = 25  # Minimum steps to consider it a new attempt\n",
    "\n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0: 'space',\n",
    "            1: 'down',\n",
    "            2: 'no_op',\n",
    "        }\n",
    "        if action != 2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        observation = self.get_observation()\n",
    "        # Get object positions and names\n",
    "        try:\n",
    "            reward, done = self.calculate_reward(self.objects_positions, {0: 'bird', 1: 'cactus', 2: 'restart', 3: 't-rex'})\n",
    "        except Exception as e:\n",
    "            print(\"Error in object detection or reward calculation:\", e)\n",
    "            reward = -10\n",
    "            done = False\n",
    "\n",
    "        info = {}\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "    def calculate_reward(self, filtered_data, names):\n",
    "        \"\"\"Calculate reward based on T-Rex position relative to obstacles\"\"\"\n",
    "        name_to_id = {v: k for k, v in names.items()}\n",
    "\n",
    "        trex_box = None\n",
    "        cactus_box = None\n",
    "        bird_box = None\n",
    "        restart_detected = False\n",
    "\n",
    "        for box in filtered_data:\n",
    "            class_id = int(box[5])\n",
    "            if class_id == name_to_id.get('t-rex'):\n",
    "                trex_box = box\n",
    "            elif class_id == name_to_id.get('cactus'):\n",
    "                cactus_box = box\n",
    "            elif class_id == name_to_id.get('bird'):\n",
    "                bird_box = box\n",
    "            elif class_id == name_to_id.get('restart'):\n",
    "                restart_detected = True\n",
    "\n",
    "        # Handle collision but don't end episode immediately\n",
    "        if restart_detected:\n",
    "            print('ðŸ’€', end=\"\")\n",
    "\n",
    "            # Only count as new collision if enough steps have passed\n",
    "            if self.steps_since_last_collision > self.min_steps_between_collisions:\n",
    "                self.collision_count += 1\n",
    "                print(f\"Collision #{self.collision_count}\", end=\" | \")\n",
    "\n",
    "            self.steps_since_last_collision = 0\n",
    "\n",
    "            # Restart the game automatically\n",
    "            time.sleep(0.3)\n",
    "            monitor_2 = self.cap.monitors[1]\n",
    "            pydirectinput.click(x=monitor_2[\"left\"] + 250, y=monitor_2[\"top\"] + 200)\n",
    "            pydirectinput.press('space')\n",
    "            time.sleep(0.3)\n",
    "\n",
    "            # End episode only after multiple collisions\n",
    "            done = self.collision_count >= self.max_collisions\n",
    "            return -100, done\n",
    "\n",
    "        # Increment steps counter\n",
    "        self.steps_since_last_collision += 1\n",
    "\n",
    "        if trex_box is None:\n",
    "            return 0, False\n",
    "\n",
    "        trex_x1, trex_y1, trex_x2, trex_y2 = [float(x) for x in trex_box[:4]]\n",
    "        trex_center_x = (trex_x1 + trex_x2) / 2\n",
    "\n",
    "        # Base reward for survival\n",
    "        reward = 1.0\n",
    "\n",
    "        # Check cactus interaction\n",
    "        if cactus_box is not None:\n",
    "            cactus_x1, cactus_y1, cactus_x2, cactus_y2 = [float(x) for x in cactus_box[:4]]\n",
    "            distance = cactus_x1 - trex_x2\n",
    "\n",
    "            if distance > 50:\n",
    "                reward += 0.5\n",
    "            elif 0 < distance < 50:\n",
    "                if trex_y2 < cactus_y1:\n",
    "                    print(\"âœ…ðŸŒµ\", end=\" | \")\n",
    "                    reward += 5.0\n",
    "                else:\n",
    "                    reward -= 2.0\n",
    "\n",
    "        # Check bird interaction\n",
    "        if bird_box is not None:\n",
    "            bird_x1, bird_y1, bird_x2, bird_y2 = [float(x) for x in bird_box[:4]]\n",
    "            distance = bird_x1 - trex_x2\n",
    "\n",
    "            if distance > 50:\n",
    "                reward += 0.5\n",
    "            elif 0 < distance < 50:\n",
    "                if trex_y2 > bird_y2 or trex_y1 < bird_y2:\n",
    "                    print(\"âœ…ðŸ¦\", end=\" | \")\n",
    "                    reward += 5.0\n",
    "                else:\n",
    "                    reward -= 2.0\n",
    "\n",
    "        print(\".\", end=\"\")\n",
    "        return reward, False\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        print(f\"\\nðŸ”„ Episode reset (Total collisions: {self.collision_count})\")\n",
    "        # Reset episode tracking variables\n",
    "        self.collision_count = 0\n",
    "        self.steps_since_last_collision = 0\n",
    "        time.sleep(0.25)\n",
    "        monitor_2 = self.cap.monitors[1]\n",
    "        pydirectinput.click(x=monitor_2[\"left\"] + 250, y=monitor_2[\"top\"] + 200)\n",
    "        pydirectinput.press('space')\n",
    "        time.sleep(0.25)\n",
    "        return self.get_observation(), {}\n",
    "\n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))\n",
    "        raw_rgb = raw[:, :, :3].astype(np.uint8)\n",
    "        gray = cv2.cvtColor(raw_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        filtered_data = getObjectPositions(gray)\n",
    "        self.objects_positions = filtered_data\n",
    "        return format_onservation(filtered_data)\n"
   ],
   "id": "db3ee1833da5e51b",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:08:59.138935Z",
     "start_time": "2025-11-13T14:08:59.105594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = WebGame()\n",
    "env.get_observation()\n",
    "# cactus-x1, bird-x1, bird-y1"
   ],
   "id": "346df2f98280aee4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     156.09,          -1,          -1], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for episodes in range(3):\n",
    "    obs = env.reset(1)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        obs, reward, done, truncated, info = env.step(env.action_space.sample())\n",
    "        total_reward += reward\n",
    "    print(\"total reward:\", total_reward, \". for episodes:\", episodes)"
   ],
   "id": "f1e81f210d46032f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:08:59.481992Z",
     "start_time": "2025-11-13T14:08:59.479561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker"
   ],
   "id": "f59c4d127b8a19bc",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:09:06.526053Z",
     "start_time": "2025-11-13T14:09:00.091028Z"
    }
   },
   "cell_type": "code",
   "source": "env_checker.check_env(env)",
   "id": "bd4b13577bc30577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      "\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      ".\n",
      "ðŸ”„ Episode reset (Total collisions: 0)\n",
      ".........."
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:10:43.925416Z",
     "start_time": "2025-11-13T14:10:43.921339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "        return True"
   ],
   "id": "331e1d7200d0b6f0",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:10:44.399096Z",
     "start_time": "2025-11-13T14:10:44.396450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ],
   "id": "30d48cb2bf5982a6",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:10:44.974739Z",
     "start_time": "2025-11-13T14:10:44.972294Z"
    }
   },
   "cell_type": "code",
   "source": "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)",
   "id": "2c05715e7c447c47",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-13T14:10:51.136002Z",
     "start_time": "2025-11-13T14:10:51.133754Z"
    }
   },
   "cell_type": "code",
   "source": "from stable_baselines3 import DQN",
   "id": "fad41f9ef99b61b2",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = DQN('MlpPolicy', env, tensorboard_log=LOG_DIR, verbose=2, buffer_size=10000, learning_starts=1000)",
   "id": "3a8fc21230c206b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.learn(total_timesteps=10000, callback=callback)",
   "id": "5da3d3aa51d539e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " # Load the trained model\n",
    "model = DQN.load('train/best_model_20000.zip')\n",
    "# model = DQN.load('yolo_model/best_model_100000.zip')\n",
    "\n",
    "# Test the model\n",
    "episodes = 5\n",
    "for episode in range(episodes):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "\n",
    "    print(f\"Episode {episode + 1} starting...\")\n",
    "\n",
    "    while not done and step_count < 1000:\n",
    "        # Use the trained model to predict actions\n",
    "        action, _ = model.predict(obs, deterministic=False)\n",
    "        print(action, end=\" | \")\n",
    "        action = int(action)  # Convert numpy array to scalar\n",
    "\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        step_count += 1\n",
    "\n",
    "        # Add small delay to see the gameplay\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    print(f\"Episode {episode + 1} finished - Total reward: {total_reward}, Steps: {step_count}\")\n"
   ],
   "id": "bb42e171c3225f3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4545e675cc655602",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
